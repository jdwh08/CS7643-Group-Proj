train:
  batch_size: 16
  lr: .0005
  n_epochs: 2
  num_workers: 4
optimizer:
  type: 'adamw'
  weight_decay: 0.05
  smoothing: 0.0
model:
  scale: 'b3'
  drop_path_rate: 0.1 #default 0.1
  hidden_dropout_prob: 0.0 #default 0
  attention_probs_dropout_prob: 0.0 #default 0
  classifier_dropout_prob: 0.1 #default 0.1
